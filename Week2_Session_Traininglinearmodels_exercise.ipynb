{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **| 모델 훈련 연습 문제**\n",
        "___\n",
        "- 출처 : 핸즈온 머신러닝 Ch04 연습문제 1, 5, 9, 10\n",
        "- 개념 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
      ],
      "metadata": {
        "id": "zCu72vDHGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?**\n",
        "___\n",
        "배치 경사 하강법\n",
        "* 특성 수에 민감하지 않음\n",
        "  * 수십만 개의 특성에서 선형 회귀를 훈련시키려면 경사 하강법이 정규방정식이나 SVD 분해보다 더 빠름"
      ],
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?**\n",
        "___\n",
        "이유: 모델이 훈련 데이터에 과적합되고 있음\\\n",
        "(참고: p.191 4.5.4 조기종료)\\\n",
        "에포크가 진행됨에 따라 알고리즘이 점차 학습되어 훈련세트에 대한 예측에러(RMSE)와 검증세트에 대한 예측 에러가 줄어듭니다. 그러나 잠시 후 감소하던 검증에러가 멈추었다가 다시 상승합니다. 모델이 훈련 데이터에 과대적합되기 시작하는 것을 의미합니다\n",
        "\n",
        "\n",
        "\n",
        "해결방안:\n",
        "* 조기종료: 검증 에러가 최소에 도달하는 즉히 훈련을 멈추는 것\n",
        "\n",
        "또는\n",
        "* 모델을 규제하는 것\n",
        "  * 자유도를 줄이면 데이터에 과대적합되기 더 어려워짐\n",
        "  * 다항회귀모델을 규제하는 간단한 방법은 다항식의 차수를 감소시키는 것\n",
        "  * 선형회귀모델에서는 보통 모델의 가중치를 제한함으로써 규제를 가합니다"
      ],
      "metadata": {
        "id": "-pDjW5XcHPOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 릿지 회귀를 사용했을 때 훈련 오차가 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 $\\alpha$를 증가시켜야 할까요 아니면 줄여야 할까요?**\n",
        "___\n"
      ],
      "metadata": {
        "id": "nM7JbsLoy7b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "릿지 회귀에서 훈련 오차와 검증 오차가 모두 높고 비슷하다면, 이는 높은 편향(bias)이 문제일 가능성이 높음.\n",
        "* 높은 편향: 모델이 너무 간단하여 데이터의 다양성과 패턴을 잡아내지 못하고 있는 것. 따라서 모델이 데이터의 복잡성을 충분히 포착하지 못하고 있는 상황\n",
        "\n",
        "이러한 경우 규제 하이퍼파라미터인 α를 줄여야\n",
        "* 릿지 회귀에서 α는 규제의 강도를 조절하는 매개변수이며\n",
        "  * 작은 α: 규제의 강도를 약화시키는 것\n",
        "  * 따라서 α를 줄이면 모델이 훈련 데이터에 더 잘 맞춰지고 -> 편향이 줄어들어 -> 모델의 복잡성이 증가 -> 훈련 오차와 검증 오차가 감소\n",
        "\n",
        "\n",
        "(cf)\\\n",
        "만약 훈련 오차와 검증 오차가 모두 높지만 훈련 오차가 더 높다: variance이 문제일 수 있음\n",
        "* 모델이 훈련 데이터에 너무 맞춰져 있어 새로운 데이터에 일반화하지 못하는 상황\n",
        "* 이 경우에는 α를 증가시켜 모델의 복잡성을 줄여야\n",
        "* 더 강한 규제를 적용하여 모델의 과적합을 줄이고 일반화 성능을 향상"
      ],
      "metadata": {
        "id": "ug7RWH_Uhluw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 다음과 같이 사용해야 하는 이유는?**\n",
        "___\n",
        "- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        "- 라쏘 회귀 대신 엘라스틱넷"
      ],
      "metadata": {
        "id": "C8tARu-ZzOGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(정답 참고: p.191)\n",
        "* 대부분 적어도 규제가 약간 있는 것이 좋음, 릿지가 기본\n",
        "* 쓰이는 특성이 몇 개 뿐이라고 의심되면 라쏘/엘라스틱\n",
        "* 특성 수가 훈련 샘플 수보다 많거나 특성 몇 개가 강하게 연관되어 있을 때는 보통 라쏘가 문제를 일으키기 때문에 라쏘보다 엘라스틱넷"
      ],
      "metadata": {
        "id": "2Fr34cFvhFXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **추가) 조기 종료를 사용한 배치 경사 하강법으로 iris 데이터를 활용해 소프트맥스 회귀를 구현해보세요(사이킷런은 사용하지 마세요)**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QIZpOEYJVIAV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqOUUktqZHnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152dc8f1-ea7e-4025-9592-4e9c8ceea57f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data',\n",
              " 'target',\n",
              " 'frame',\n",
              " 'target_names',\n",
              " 'DESCR',\n",
              " 'feature_names',\n",
              " 'filename',\n",
              " 'data_module']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "list(iris.keys())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.data[:, (2,3)] # 꽃잎 길이, 꽃잎 너비\n",
        "y = iris[\"target\"]"
      ],
      "metadata": {
        "id": "VJikI9rZm1bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqSKfySeZHnG"
      },
      "source": [
        "모든 샘플에 대해 편향 항을 추가 ($x_0 = 1$)\n",
        "\n",
        "가장 쉬운 옵션은 사이킷런의 `add_dummy_feature()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2lVPD_FZHnG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X_b = np.c_[np.ones(len(X)), X]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1utNJ7spW3h",
        "outputId": "ceb39357-e893-4cb3-b77c-901ba5096fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta = np.random.randn(3,3)"
      ],
      "metadata": {
        "id": "bN4i2QKmpYWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql6nmBhtpap8",
        "outputId": "5b18d952-5b19-42c9-f0ba-32918e6b919c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size = 0.2, random_state=42)"
      ],
      "metadata": {
        "id": "f4mPZxe3pbyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(categories='auto')\n",
        "y_train_ohe = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
        "y_test_ohe = encoder.fit_transform(y_test.reshape(-1, 1)).toarray()"
      ],
      "metadata": {
        "id": "sETHBJi-wApX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_ohe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vwDtOkAwZKX",
        "outputId": "dac0d298-62c9-4fe3-c901-ffa14284f773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**정규화/Scaling?**"
      ],
      "metadata": {
        "id": "rM1DEn6rMOMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "  exps = np.exp(z)\n",
        "  exp_sum = np.sum(exps, axis=1, keepdims = True)\n",
        "  return exps/exp_sum"
      ],
      "metadata": {
        "id": "tvf5GfI2zt2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_x = X_train @ theta\n",
        "s_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZYr-Sjt0TNk",
        "outputId": "515b687b-513f-4220-dd42-7bd48094e66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 0.1 # 학습률\n",
        "n_epochs = 1000\n",
        "m = len(X_train) # 샘플 개수\n",
        "history=[]\n",
        "epsilon = 1e-7\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  Y_proba = softmax(s_x)\n",
        "  loss = -np.mean(np.sum(y_train_ohe * np.log(Y_proba + epsilon), axis=1))\n",
        "  error = Y_proba - y_train_ohe # (#,3)\n",
        "  gradients = (1/m) * (X_train.T.dot(error))\n",
        "  theta = theta - eta * gradients\n",
        "  history.append(loss)"
      ],
      "metadata": {
        "id": "HQdwHtyqzpZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMsw1nB2136D",
        "outputId": "0e4ab4f0-de3d-4ffe-c06e-8a6722e0c160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  30.09227267,  -64.10762928,   31.04019691],\n",
              "       [  47.12679561, -224.13731176,  176.0506845 ],\n",
              "       [   8.52150047,  -72.54060885,   65.14668597]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}